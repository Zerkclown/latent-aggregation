{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from la.data.datamodule import MetaData\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "from la.data.dataset import MyDataset\n",
    "from la.modules.module import CNN\n",
    "from la.pl_modules.pl_module import MyLightningModule\n",
    "\n",
    "try:\n",
    "    # be ready for 3.10 when it drops\n",
    "    from enum import StrEnum\n",
    "except ImportError:\n",
    "    from backports.strenum import StrEnum\n",
    "from enum import auto\n",
    "from nn_core.common import PROJECT_ROOT\n",
    "\n",
    "import hdf5storage\n",
    "from torch.nn.functional import mse_loss, pairwise_distance\n",
    "from torchmetrics.functional import pearson_corrcoef, spearman_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tueplots import bundles\n",
    "\n",
    "seed_everything(43)\n",
    "bundles.icml2022()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit1, digit2 = 4, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = PROJECT_ROOT / \"data\" / \"MNIST\"\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist = MNIST(\n",
    "    data_path,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "initialize(config_path=\"../conf\")\n",
    "cfg = compose(config_name=\"prelim_exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetaData(class_vocab=mnist.class_to_idx)\n",
    "print(mnist.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1: MyLightningModule = MyLightningModule.load_from_checkpoint(\n",
    "    \"checkpoints/missing_6/checkpoint.ckpt\", metadata=metadata\n",
    ")\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2: MyLightningModule = MyLightningModule.load_from_checkpoint(\n",
    "    \"checkpoints/missing_9/checkpoint.ckpt\", metadata=metadata\n",
    ")\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5000\n",
    "dataset = MyDataset(samples=mnist, split=\"test\", class_vocab=mnist.class_to_idx)\n",
    "dataloader = DataLoader(dataset, shuffle=False, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds1 = []\n",
    "for batch in dataloader:\n",
    "    embeds1.append(model1.model(batch[\"x\"])[\"embeds\"])\n",
    "embeds1 = torch.cat(embeds1, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds2 = []\n",
    "for batch in dataloader:\n",
    "    embeds2.append(model2.model(batch[\"x\"])[\"embeds\"])\n",
    "embeds2 = torch.cat(embeds2, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMAP = \"jet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_limit: int = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (num_shapes, latent_dim)\n",
    "abs_space1 = embeds1.detach()[:sample_limit]\n",
    "abs_space2 = embeds2.detach()[:sample_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = mnist.targets[:num_samples]\n",
    "\n",
    "digit1_mask = targets == digit1\n",
    "digit2_mask = targets == digit2\n",
    "\n",
    "unseen_classes_mask = digit1_mask | digit2_mask\n",
    "seen_classes_mask = ~unseen_classes_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_seen_classes = targets[seen_classes_mask]\n",
    "abs_space1_seen_classes = abs_space1[seen_classes_mask]\n",
    "abs_space2_seen_classes = abs_space2[seen_classes_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_unseen_classes = targets[unseen_classes_mask]\n",
    "abs_space1_unseen_classes = abs_space1[unseen_classes_mask]\n",
    "abs_space2_unseen_classes = abs_space2[unseen_classes_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(targets.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort items by digit label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_indices: torch.Tensor = targets_unseen_classes.sort().indices\n",
    "abs_space1_unseen_classes: torch.Tensor = abs_space1_unseen_classes[sort_indices, :]\n",
    "abs_space2_unseen_classes: torch.Tensor = abs_space2_unseen_classes[sort_indices, :]\n",
    "labels: torch.Tensor = targets_unseen_classes[sort_indices]\n",
    "\n",
    "assert abs_space1_unseen_classes.shape == abs_space2_unseen_classes.shape\n",
    "assert abs_space1_unseen_classes.size(0) == labels.size(0)\n",
    "abs_space1_unseen_classes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor selection\n",
    "Only pick anchors among shared classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples, embedding_dim = abs_space1_seen_classes.size()\n",
    "num_anchors: int = embedding_dim\n",
    "\n",
    "anchor_idxs = list(range(num_samples))\n",
    "random.shuffle(anchor_idxs)\n",
    "anchor_idxs = anchor_idxs[:num_anchors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_space1 = abs_space1_unseen_classes\n",
    "abs_space2 = abs_space2_unseen_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_abs_space1: torch.Tensor = F.normalize(abs_space1, p=2, dim=-1)\n",
    "norm_abs_space2: torch.Tensor = F.normalize(abs_space2, p=2, dim=-1)\n",
    "\n",
    "assert norm_abs_space1.shape == norm_abs_space2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_abs_space1_seen_classes = F.normalize(abs_space1_seen_classes, p=2, dim=-1)\n",
    "norm_abs_space2_seen_classes = F.normalize(abs_space2_seen_classes, p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space1_anchors = norm_abs_space1_seen_classes[anchor_idxs]\n",
    "space2_anchors = norm_abs_space2_seen_classes[anchor_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from la.utils.relative_analysis import plot_pairwise_dist\n",
    "\n",
    "plot_pairwise_dist(space1=abs_space1, space2=abs_space2, prefix=\"Absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from la.utils.relative_analysis import self_sim_comparison\n",
    "\n",
    "self_sim_comparison(space1=abs_space1, space2=abs_space2, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from la.utils.relative_analysis import plot_self_dist\n",
    "\n",
    "plot_self_dist(space1=abs_space1, space2=abs_space2, prefix=\"Absolute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_space1 = norm_abs_space1 @ space1_anchors.T\n",
    "rel_space2 = norm_abs_space2 @ space2_anchors.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from la.utils.relative_analysis import plot_pairwise_dist\n",
    "\n",
    "plot_pairwise_dist(space1=rel_space1, space2=rel_space2, prefix=\"Relative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from la.utils.relative_analysis import self_sim_comparison\n",
    "\n",
    "self_sim_comparison(space1=rel_space1, space2=rel_space2, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from la.utils.relative_analysis import plot_self_dist\n",
    "\n",
    "plot_self_dist(space1=rel_space1, space2=rel_space2, prefix=\"Relative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from la.utils.relative_analysis import Reduction, reduce\n",
    "\n",
    "x_header = [reduction.upper() for reduction in Reduction]\n",
    "y_header = [\"Absolute Space 1\", \"Absolute Space 2\", \"Relative Space 1\", \"Relative Space 2\"]\n",
    "\n",
    "spaces = [\n",
    "    [\n",
    "        *reduce(space1=abs_space1, space2=abs_space2, reduction=reduction),\n",
    "        *reduce(space1=rel_space1, space2=rel_space2, reduction=reduction),\n",
    "    ]\n",
    "    for reduction in Reduction\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from la.utils.relative_analysis import plot_space_grid\n",
    "\n",
    "fig = plot_space_grid(x_header=x_header, y_header=y_header, spaces=spaces, c=labels)\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
