{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from nn_core.common import PROJECT_ROOT\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from la.utils.utils import MyDatasetDict\n",
    "\n",
    "try:\n",
    "    # be ready for 3.10 when it drops\n",
    "    from enum import StrEnum\n",
    "except ImportError:\n",
    "    from backports.strenum import StrEnum\n",
    "from pytorch_lightning import seed_everything\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import namedtuple\n",
    "import timm\n",
    "from transformers import AutoModel, AutoProcessor\n",
    "from typing import Sequence, List\n",
    "from PIL.Image import Image\n",
    "from tqdm import tqdm\n",
    "import functools\n",
    "from timm.data import resolve_data_config\n",
    "from datasets import load_dataset, load_from_disk, Dataset, DatasetDict\n",
    "import torchvision\n",
    "import torch\n",
    "from timm.data import create_transform\n",
    "from la.utils.cka import CKA\n",
    "\n",
    "import logging\n",
    "from typing import Any, Sequence, Tuple, Union, Dict\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import hydra\n",
    "import torch\n",
    "from hydra.utils import instantiate\n",
    "from nn_core.model_logging import NNLogger\n",
    "from omegaconf import DictConfig\n",
    "from torch.optim import Optimizer\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "\n",
    "from la.pl_modules.pl_module import MyLightningModule\n",
    "\n",
    "pylogger = logging.getLogger(__name__)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "from la.utils.utils import add_tensor_column\n",
    "from datasets import concatenate_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: MyDatasetDict = MyDatasetDict.load_from_disk(\"../data/cifar100/partitioned\")\n",
    "\n",
    "num_tasks = data[\"metadata\"][\"num_tasks\"]\n",
    "\n",
    "for task_ind in range(num_tasks + 1):\n",
    "    data[f\"task_{task_ind}_anchors\"] = data[\"anchors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_func = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in {\"train\", \"val\", \"test\", \"anchors\"}:\n",
    "    for task_ind in range(num_tasks + 1):\n",
    "        data[f\"task_{task_ind}_{mode}\"] = data[f\"task_{task_ind}_{mode}\"].map(\n",
    "            lambda x: {\"x\": transform_func(x[\"x\"])}, batched=False\n",
    "        )\n",
    "        data[f\"task_{task_ind}_{mode}\"].set_format(\"torch\", columns=[\"x\", \"y\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nn_core.model_logging import NNLogger\n",
    "from kornia.augmentation import (\n",
    "    ColorJiggle,\n",
    "    RandomChannelShuffle,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomThinPlateSpline,\n",
    "    RandomRotation,\n",
    "    RandomCrop,\n",
    "    Normalize,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class ShakeShake(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x1, x2, training=True):\n",
    "        if training:\n",
    "            alpha = torch.cuda.FloatTensor(x1.size(0)).uniform_()\n",
    "            alpha = alpha.view(alpha.size(0), 1, 1, 1).expand_as(x1)\n",
    "        else:\n",
    "            alpha = 0.5\n",
    "        return alpha * x1 + (1 - alpha) * x2\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        beta = torch.cuda.FloatTensor(grad_output.size(0)).uniform_()\n",
    "        beta = beta.view(beta.size(0), 1, 1, 1).expand_as(grad_output)\n",
    "        beta = Variable(beta)\n",
    "\n",
    "        return beta * grad_output, (1 - beta) * grad_output, None\n",
    "\n",
    "\n",
    "class Shortcut(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride):\n",
    "        super(Shortcut, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch // 2, 1, stride=1, padding=0, bias=False)\n",
    "        self.conv2 = nn.Conv2d(in_ch, out_ch // 2, 1, stride=1, padding=0, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(x)\n",
    "\n",
    "        h1 = F.avg_pool2d(h, 1, self.stride)\n",
    "        h1 = self.conv1(h1)\n",
    "\n",
    "        h2 = F.avg_pool2d(F.pad(h, (-1, 1, -1, 1)), 1, self.stride)\n",
    "        h2 = self.conv2(h2)\n",
    "\n",
    "        h = torch.cat((h1, h2), 1)\n",
    "        return self.bn(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class ShakeBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super(ShakeBlock, self).__init__()\n",
    "        self.equal_io = in_ch == out_ch\n",
    "        self.shortcut = self.equal_io and None or Shortcut(in_ch, out_ch, stride=stride)\n",
    "\n",
    "        self.branch1 = self._make_branch(in_ch, out_ch, stride)\n",
    "        self.branch2 = self._make_branch(in_ch, out_ch, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.branch1(x)\n",
    "        h2 = self.branch2(x)\n",
    "        h = ShakeShake.apply(h1, h2, self.training)\n",
    "        h0 = x if self.equal_io else self.shortcut(x)\n",
    "        return h + h0\n",
    "\n",
    "    def _make_branch(self, in_ch, out_ch, stride=1):\n",
    "        return nn.Sequential(\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "        )\n",
    "\n",
    "\n",
    "class ShakeResNet(nn.Module):\n",
    "    def __init__(self, depth, w_base, label):\n",
    "        super(ShakeResNet, self).__init__()\n",
    "        n_units = (depth - 2) / 6\n",
    "\n",
    "        in_chs = [16, w_base, w_base * 2, w_base * 4]\n",
    "        self.in_chs = in_chs\n",
    "\n",
    "        self.c_in = nn.Conv2d(3, in_chs[0], 3, padding=1)\n",
    "        self.layer1 = self._make_layer(n_units, in_chs[0], in_chs[1])\n",
    "        self.layer2 = self._make_layer(n_units, in_chs[1], in_chs[2], 2)\n",
    "        self.layer3 = self._make_layer(n_units, in_chs[2], in_chs[3], 2)\n",
    "        self.fc_out = nn.Linear(in_chs[3], label)\n",
    "\n",
    "        # Initialize paramters\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.c_in(x)\n",
    "        h = self.layer1(h)\n",
    "        h = self.layer2(h)\n",
    "        h = self.layer3(h)\n",
    "        h = F.avg_pool2d(h, 8)\n",
    "        embeds = h.view(-1, self.in_chs[3])\n",
    "        h = F.relu(embeds)\n",
    "\n",
    "        h = self.fc_out(h)\n",
    "        return {\"logits\": h, \"embeds\": embeds}\n",
    "\n",
    "    def _make_layer(self, n_units, in_ch, out_ch, stride=1):\n",
    "        layers = []\n",
    "        for i in range(int(n_units)):\n",
    "            layers.append(ShakeBlock(in_ch, out_ch, stride=stride))\n",
    "            in_ch, stride = out_ch, 1\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmentation(nn.Module):\n",
    "    \"\"\"Module to perform data augmentation using Kornia on torch tensors.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.transforms = nn.Sequential(\n",
    "            RandomHorizontalFlip(p=0.5),\n",
    "            RandomRotation(degrees=30),\n",
    "            RandomCrop((input_dim, input_dim)),\n",
    "            ColorJiggle(0.2, 0.2, 0.2, 0.2, p=0.5),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x_out = self.transforms(x)  # BxCxHxW\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(MyLightningModule):\n",
    "    logger: NNLogger\n",
    "\n",
    "    def __init__(self, num_classes, input_dim, model, *args, **kwargs) -> None:\n",
    "        super().__init__(num_classes=num_classes, input_dim=input_dim, *args, **kwargs)\n",
    "\n",
    "        self.save_hyperparameters(logger=False, ignore=(\"metadata\",))\n",
    "\n",
    "        self.model = model\n",
    "        self.data_augm = DataAugmentation(input_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Dict:\n",
    "        \"\"\"Method for the forward pass.\n",
    "\n",
    "        'training_step', 'validation_step' and 'test_step' should call\n",
    "        this method in order to compute the output predictions and the loss.\n",
    "\n",
    "        Returns:\n",
    "            output_dict: forward output containing the predictions (output logits ecc...) and the loss if any.\n",
    "        \"\"\"\n",
    "        model_out = self.model(x)\n",
    "\n",
    "        return model_out\n",
    "\n",
    "    def configure_optimizers(\n",
    "        self,\n",
    "    ) -> Union[Optimizer, Tuple[Sequence[Optimizer], Sequence[Any]]]:\n",
    "        \"\"\"Choose what optimizers and learning-rate schedulers to use in your optimization.\n",
    "\n",
    "        Normally you'd need one. But in the case of GANs or similar you might have multiple.\n",
    "\n",
    "        Return:\n",
    "            Any of these 6 options.\n",
    "            - Single optimizer.\n",
    "            - List or Tuple - List of optimizers.\n",
    "            - Two lists - The first list has multiple optimizers, the second a list of LR schedulers (or lr_dict).\n",
    "            - Dictionary, with an 'optimizer' key, and (optionally) a 'lr_scheduler'\n",
    "              key whose value is a single LR scheduler or lr_dict.\n",
    "            - Tuple of dictionaries as described, with an optional 'frequency' key.\n",
    "            - None - Fit will run without any optimizer.\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def _weights_init(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option=\"A\", input_dim=32, outputs=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        # self.bn1 = nn.LayerNorm(input_dim)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        # self.bn2 = nn.LayerNorm(input_dim)\n",
    "        self.outputs = outputs\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes),\n",
    "                # nn.LayerNorm(input_dim),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out1 = self.conv1(x)\n",
    "        conv_out1 = self.bn1(conv_out1)\n",
    "        out1 = F.relu(conv_out1)\n",
    "\n",
    "        conv_out2 = self.conv2(out1)\n",
    "        conv_out2 = self.bn2(conv_out2)\n",
    "\n",
    "        out2 = conv_out2\n",
    "        out2 += self.shortcut(x)\n",
    "\n",
    "        self.outputs.extend([conv_out1, conv_out2])\n",
    "\n",
    "        return out2\n",
    "\n",
    "\n",
    "class ResNetModule(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=100):\n",
    "        super(ResNetModule, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "        )\n",
    "\n",
    "        self.outputs = []\n",
    "\n",
    "        self.layer1 = self._make_layer(block, planes=16, num_blocks=num_blocks[0], stride=1, input_dim=32)\n",
    "        self.layer2 = self._make_layer(block, planes=32, num_blocks=num_blocks[1], stride=2, input_dim=16)\n",
    "        self.layer3 = self._make_layer(block, planes=64, num_blocks=num_blocks[2], stride=2, input_dim=8)\n",
    "\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride, input_dim):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, input_dim=input_dim, outputs=self.outputs))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.outputs.clear()\n",
    "\n",
    "        # (B, C, H, W)\n",
    "        self.outputs.append(x)\n",
    "\n",
    "        out = self.layer0(x)\n",
    "        self.outputs.append(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.layer1(out)\n",
    "\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.layer2(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.layer3(out)\n",
    "\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "\n",
    "        embeds = out.view(out.size(0), -1)\n",
    "\n",
    "        out = F.relu(embeds)\n",
    "\n",
    "        out = self.linear(embeds)\n",
    "        self.outputs.append(out)\n",
    "\n",
    "        return {\"embeds\": embeds, \"logits\": out, \"outputs\": self.outputs}\n",
    "\n",
    "\n",
    "def resnet20():\n",
    "    return ResNet(BasicBlock, [3, 3, 3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "def train_model(train_data, val_data, anchors, test_data, seed):\n",
    "    seed_everything(seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # module = ResNetModule(BasicBlock, [3, 3, 3], num_classes=100)\n",
    "    module = ShakeResNet(depth=20, w_base=16, label=100)\n",
    "    model = ResNet(num_classes=100, model=module, input_dim=32, transform_func=None)\n",
    "\n",
    "    model.configure_optimizers()\n",
    "\n",
    "    val_dataloader = DataLoader(val_data, batch_size=128, shuffle=False, num_workers=8)\n",
    "\n",
    "    train_and_anchors = concatenate_datasets([train_data, anchors])\n",
    "\n",
    "    dataloader = DataLoader(train_and_anchors, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=1,\n",
    "        max_epochs=100,\n",
    "        precision=32,\n",
    "        callbacks=[EarlyStopping(monitor=\"loss/val\", patience=10, mode=\"min\")],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, dataloader, val_dataloader)\n",
    "\n",
    "    test_dataloader = DataLoader(test_data, batch_size=128, shuffle=False, num_workers=8)\n",
    "\n",
    "    trainer.test(model, test_dataloader)\n",
    "    model.eval()\n",
    "\n",
    "    model = model.cuda()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_samples(model, test_data, anchors):\n",
    "\n",
    "    test_dataloader = DataLoader(test_data, batch_size=128, shuffle=False, num_workers=8)\n",
    "\n",
    "    test_embeds = []\n",
    "    for batch in test_dataloader:\n",
    "        x, y = batch[\"x\"], batch[\"y\"]\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "        embeds = model(x)[\"embeds\"]\n",
    "        test_embeds.extend(embeds.detach())\n",
    "\n",
    "    test_embeds = torch.stack(test_embeds)\n",
    "\n",
    "    anchor_dataloader = DataLoader(anchors, batch_size=128, shuffle=False, num_workers=8)\n",
    "    anchor_embeds = []\n",
    "    for batch in anchor_dataloader:\n",
    "        x, y = batch[\"x\"], batch[\"y\"]\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "        embeds = model(x)[\"embeds\"]\n",
    "        anchor_embeds.extend(embeds.detach())\n",
    "\n",
    "    anchor_embeds = torch.stack(anchor_embeds)\n",
    "\n",
    "    return test_embeds, anchor_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_relatives(test_embeds, anchor_embeds, num_anchors, seed):\n",
    "    seed_everything(seed)\n",
    "\n",
    "    anchor_embeds = anchor_embeds[:num_anchors]\n",
    "    norm_anchors = F.normalize(anchor_embeds, p=2, dim=-1)\n",
    "\n",
    "    abs_space = F.normalize(test_embeds, p=2, dim=-1)\n",
    "\n",
    "    rel_space = abs_space @ norm_anchors.T\n",
    "\n",
    "    return rel_space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same data, different seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_same = train_model(data[\"task_1_train\"], data[\"task_1_val\"], data[\"task_1_anchors\"], data[\"task_0_test\"], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_same = train_model(\n",
    "    data[\"task_1_train\"], data[\"task_1_val\"], data[\"task_1_anchors\"], data[\"task_0_test\"], seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_anchors = 256\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeds, anchor_embeds = embed_samples(\n",
    "    model1_same,\n",
    "    data[\"task_0_test\"],\n",
    "    data[\"task_1_anchors\"],\n",
    ")\n",
    "\n",
    "rel_space = compute_relatives(test_embeds, anchor_embeds, num_anchors, seed)\n",
    "\n",
    "test_data1 = add_tensor_column(data[\"task_0_test\"], \"relative_embeddings\", rel_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeds, anchor_embeds = embed_samples(\n",
    "    model2_same,\n",
    "    data[\"task_0_test\"],\n",
    "    data[\"task_1_anchors\"],\n",
    ")\n",
    "\n",
    "rel_space = compute_relatives(test_embeds, anchor_embeds, num_anchors, seed)\n",
    "\n",
    "test_data2 = add_tensor_column(data[\"task_0_test\"], \"relative_embeddings\", rel_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1.set_format(\"torch\", columns=[\"relative_embeddings\", \"id\"])\n",
    "test_data2.set_format(\"torch\", columns=[\"relative_embeddings\", \"id\"])\n",
    "test_data1 = test_data1.sort(\"id\")\n",
    "test_data2 = test_data2.sort(\"id\")\n",
    "assert torch.all(test_data1[\"id\"] == test_data2[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cka = CKA(mode=\"linear\", device=\"cuda\")\n",
    "\n",
    "cka_score = cka(test_data1[\"relative_embeddings\"], test_data2[\"relative_embeddings\"])\n",
    "print(cka_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate block structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(data[\"task_0_test\"], batch_size=512, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def CKA_matrix(embeds1, embeds2):\n",
    "\n",
    "    n1, n2 = len(embeds1), len(embeds2)\n",
    "\n",
    "    cka_score_matrix = [[0.0 for i in range(n1)] for j in range(n2)]\n",
    "\n",
    "    for i, layer_i_embed in enumerate(embeds1):\n",
    "        for j, layer_j_embed in enumerate(embeds2):\n",
    "\n",
    "            layer_i_embed = layer_i_embed.view(layer_i_embed.size(0), -1)\n",
    "            layer_j_embed = layer_j_embed.view(layer_j_embed.size(0), -1)\n",
    "\n",
    "            cka_score = cka(layer_i_embed, layer_j_embed)\n",
    "\n",
    "            cka_score_matrix[n1 - 1 - i][j] = cka_score.cpu().detach().numpy()\n",
    "\n",
    "    cka_score_matrix = np.array(cka_score_matrix)\n",
    "\n",
    "    return cka_score_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pretty heatmap with colorbar\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_heatmap(heatmap, with_values=False):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    sns.heatmap(heatmap, ax=ax, cmap=\"rocket\", square=True, cbar_kws={\"label\": \"CKA Score\"})\n",
    "    ax.set_yticklabels([str(i) for i in range(len(heatmap) - 1, -1, -1)])\n",
    "    if with_values:\n",
    "        for i in range(heatmap.shape[0]):\n",
    "            for j in range(heatmap.shape[1]):\n",
    "                ax.text(j + 0.5, i + 0.5, f\"{heatmap[i, j]:.2f}\", ha=\"center\", va=\"center\", color=\"w\")\n",
    "    ax.set_xlabel(\"Layer\")\n",
    "    ax.set_ylabel(\"Layer\")\n",
    "    ax.set_title(\"CKA Score Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))\n",
    "\n",
    "x, y = batch[\"x\"], batch[\"y\"]\n",
    "x = x.cuda()\n",
    "y = y.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds1 = model1_same(x)[\"outputs\"]\n",
    "\n",
    "cka_score_matrix = CKA_matrix(embeds1, embeds1)\n",
    "print(cka_score_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(cka_score_matrix, with_values=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds1 = model1_same(x)[\"outputs\"]\n",
    "embeds2 = model2_same(x)[\"outputs\"]\n",
    "\n",
    "cka_score_matrix = CKA_matrix(embeds1, embeds2)\n",
    "print(cka_score_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(cka_score_matrix, with_values=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = train_model(data[\"task_1_train\"], data[\"task_1_anchors\"], data[\"task_0_test\"], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = train_model(data[\"task_2_train\"], data[\"task_2_anchors\"], data[\"task_0_test\"], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeds, anchor_embeds = embed_samples(\n",
    "    model1,\n",
    "    data[\"task_0_test\"],\n",
    "    data[\"task_1_anchors\"],\n",
    ")\n",
    "\n",
    "rel_space = compute_relatives(test_embeds, anchor_embeds, num_anchors, seed)\n",
    "\n",
    "test_data1 = add_tensor_column(data[\"task_0_test\"], \"relative_embeddings\", rel_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeds, anchor_embeds = embed_samples(\n",
    "    model2,\n",
    "    data[\"task_0_test\"],\n",
    "    data[\"task_2_anchors\"],\n",
    ")\n",
    "\n",
    "rel_space = compute_relatives(test_embeds, anchor_embeds, num_anchors, seed)\n",
    "\n",
    "test_data2 = add_tensor_column(data[\"task_0_test\"], \"relative_embeddings\", rel_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1.set_format(\"torch\", columns=[\"relative_embeddings\"])\n",
    "test_data2.set_format(\"torch\", columns=[\"relative_embeddings\"])\n",
    "test_data1 = test_data1.sort(\"id\")\n",
    "test_data2 = test_data2.sort(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from la.utils.cka import CKA\n",
    "\n",
    "cka = CKA(mode=\"linear\", device=\"cuda\")\n",
    "\n",
    "cka_score = cka(test_data1[\"relative_embeddings\"], test_data2[\"relative_embeddings\"])\n",
    "print(cka_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered1 = test_data1[\"relative_embeddings\"] - test_data1[\"relative_embeddings\"].mean(dim=0, keepdim=True)\n",
    "centered2 = test_data2[\"relative_embeddings\"] - test_data2[\"relative_embeddings\"].mean(dim=0, keepdim=True)\n",
    "\n",
    "cka_score = cka(centered1, centered2)\n",
    "print(cka_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "la",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
