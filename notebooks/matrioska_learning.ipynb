{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from typing import Dict, List\n",
    "from la.data.my_dataset_dict import MyDatasetDict\n",
    "\n",
    "initialize(version_base=None, config_path=str(\"../conf\"), job_name=\"matrioska_learning\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_core.common import PROJECT_ROOT\n",
    "\n",
    "# Instantiate torchvision dataset\n",
    "cfg = compose(config_name=\"matrioska_learning\", overrides=[])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from la.utils.io_utils import add_ids_to_dataset, load_data\n",
    "from la.utils.io_utils import preprocess_dataset\n",
    "\n",
    "\n",
    "original_dataset = dataset = load_data(cfg)  # .shard(num_shards=10, index=0)  # TODO remove sharding when done develop\n",
    "dataset = preprocess_dataset(dataset, cfg)\n",
    "dataset = add_ids_to_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = dataset[\"train\"][0][\"x\"].shape[1]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf specific variables\n",
    "# (if a dataset change is needed, it is enough to redefine these variables...)\n",
    "class_names = original_dataset[\"train\"].features[\"fine_label\"].names\n",
    "class_idxs = [original_dataset[\"train\"].features[\"fine_label\"].str2int(class_name) for class_name in class_names]\n",
    "\n",
    "class_names, class_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Result:\n",
    "    matrioska_idx: int\n",
    "    num_train_classes: int\n",
    "    metric_name: str\n",
    "    score: float"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define matrioska datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define matrioska parameters... just start with the first two classes\n",
    "MATRIOSKA_START_NCLASSES = [0, 1]\n",
    "LIMIT_N_CLASSES = 30\n",
    "remanining_classes = sorted((set(class_idxs) - set(MATRIOSKA_START_NCLASSES)))[:LIMIT_N_CLASSES]\n",
    "MATRIOSKA_START_NCLASSES, remanining_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate matrioska classes\n",
    "matrioskaclasses = [set(MATRIOSKA_START_NCLASSES + remanining_classes[:i]) for i in range(len(remanining_classes) + 1)]\n",
    "matrioskaclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate associated datasets\n",
    "# TODO: do we want to have the same number of samples in all the datasets?\n",
    "# I think not. This is more fair, if this works we are in the worst case scenario.\n",
    "matrioskaidx2dataset = {\n",
    "    i: dataset.filter(lambda row: row[\"y\"] in matrioskaclasses[i]) for i in range(len(matrioskaclasses))\n",
    "}\n",
    "\n",
    "# Note that we are using the prefix convention for the classes, thus we have consistency\n",
    "# between local and global classes ids... let's stay with that it is easier\n",
    "matrioskaidx2dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train matrioska models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from typing import Dict\n",
    "import tqdm\n",
    "import torch\n",
    "\n",
    "matrioskaidx2dataset\n",
    "\n",
    "matrioskaidx2embeds: Dict[str, DatasetDict] = {\n",
    "    f\"matrioska{matrioska_idx}\": DatasetDict(train=DatasetDict(), test=DatasetDict())\n",
    "    for matrioska_idx in range(len(matrioskaclasses))\n",
    "}\n",
    "len(matrioskaidx2embeds), matrioskaidx2embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "HF_EMBEDDING_DATASET_PATH = PROJECT_ROOT / \"matrioska_learning\" / \"hf_embedding_dataset\"\n",
    "\n",
    "\n",
    "def embed_and_save_samples(matrioskaidx2embeds, dataset, model, matrioska_idx, batch_size=1024) -> Dict:\n",
    "    modes = [\"train\", \"test\"]\n",
    "\n",
    "    model.cuda().eval()\n",
    "\n",
    "    for mode in modes:\n",
    "        mode_embeddings = []\n",
    "        mode_ids = []\n",
    "        mode_labels = []\n",
    "        mode_loader = DataLoader(\n",
    "            dataset[mode],\n",
    "            batch_size=batch_size,\n",
    "            pin_memory=True,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "        )\n",
    "        for batch in tqdm(mode_loader, desc=f\"Embedding {mode} samples for {matrioska_idx}th matrioska\"):\n",
    "            x = batch[\"x\"].to(\"cuda\")\n",
    "            mode_embeddings.extend(model(x)[\"embeds\"].detach())\n",
    "            mode_ids.extend(batch[\"id\"])\n",
    "            mode_labels.extend(batch[\"y\"])\n",
    "\n",
    "        matrioskaidx2embeds[f\"matrioska{matrioska_idx}\"][mode] = Dataset.from_dict(\n",
    "            {\n",
    "                \"embeds\": mode_embeddings,\n",
    "                \"id\": mode_ids,\n",
    "                \"y\": mode_labels,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    model.cpu()\n",
    "    matrioskaidx2embeds[f\"matrioska{matrioska_idx}\"].save_to_disk(\n",
    "        HF_EMBEDDING_DATASET_PATH / f\"matrioska{matrioska_idx}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from nn_core.callbacks import NNTemplateCore\n",
    "from nn_core.model_logging import NNLogger\n",
    "from nn_core.serialization import NNCheckpointIO\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Callback\n",
    "\n",
    "from la.utils.utils import build_callbacks\n",
    "\n",
    "\n",
    "matrioskaidx2model = {}\n",
    "\n",
    "\n",
    "for i in range(len(matrioskaclasses)):\n",
    "    print(f\"Training model {i}...\")\n",
    "\n",
    "    model: pl.LightningModule = hydra.utils.instantiate(\n",
    "        cfg.nn.model,\n",
    "        _recursive_=False,\n",
    "        num_classes=len(matrioskaclasses[i]),\n",
    "        model=cfg.nn.model.model,\n",
    "        input_dim=img_size,\n",
    "    )\n",
    "\n",
    "    processed_dataset = matrioskaidx2dataset[i].map(\n",
    "        desc=f\"Preprocessing samples\",\n",
    "        function=lambda x: {\"x\": model.transform_func(x[\"x\"])},\n",
    "    )\n",
    "    processed_dataset.set_format(type=\"torch\", columns=[\"x\", \"y\", \"id\"])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        processed_dataset[\"train\"],\n",
    "        batch_size=512,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        processed_dataset[\"test\"],\n",
    "        batch_size=512,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "    )\n",
    "\n",
    "    template_core: NNTemplateCore = NNTemplateCore(\n",
    "        restore_cfg=cfg.train.get(\"restore\", None),\n",
    "    )\n",
    "    callbacks: List[Callback] = build_callbacks(cfg.train.callbacks, template_core)\n",
    "\n",
    "    storage_dir: str = cfg.core.storage_dir\n",
    "\n",
    "    logger: NNLogger = NNLogger(logging_cfg=cfg.train.logging, cfg=cfg, resume_id=template_core.resume_id)\n",
    "\n",
    "    # Use this in case we need to restore models, search for it in the wandb UI\n",
    "    logger.experiment.config[\"matrioska_idx\"] = i\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=storage_dir,\n",
    "        plugins=[NNCheckpointIO(jailing_dir=logger.run_dir)],\n",
    "        logger=logger,\n",
    "        callbacks=callbacks,\n",
    "        **cfg.train.trainer,\n",
    "    )\n",
    "    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "    matrioskaidx2model[i] = trainer.model.eval().cpu().requires_grad_(False)\n",
    "\n",
    "    embed_and_save_samples(matrioskaidx2embeds, processed_dataset, matrioskaidx2model[i], i, batch_size=1024)\n",
    "    logger.experiment.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalute matrioska models with classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "from nn_core.common import PROJECT_ROOT\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import datasets\n",
    "\n",
    "HF_EMBEDDING_DATASET_PATH = PROJECT_ROOT / \"matrioska_learning\" / \"hf_embedding_dataset\"\n",
    "N_MATRIOSKA = 21\n",
    "\n",
    "matrioskaidx2embeds = {\n",
    "    i: datasets.load_from_disk(HF_EMBEDDING_DATASET_PATH / f\"matrioska{i}\") for i in range(N_MATRIOSKA)\n",
    "}\n",
    "len(matrioskaidx2embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which classes to evaluate on -- it may be interesting to change this\n",
    "EVALUATION_CLASSES = {0, 1, 2, 3, 4}\n",
    "EVALUATION_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from nn_core.callbacks import NNTemplateCore\n",
    "from nn_core.model_logging import NNLogger\n",
    "from nn_core.serialization import NNCheckpointIO\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Callback\n",
    "from la.pl_modules.classifier import Classifier\n",
    "\n",
    "from la.utils.utils import build_callbacks\n",
    "\n",
    "performance = []\n",
    "\n",
    "# Iterate over models that have been trained on at least EVALUATION_CLASSES\n",
    "for matrioska_idx, embeds in list(matrioskaidx2embeds.items())[len(EVALUATION_CLASSES) - 2 :]:\n",
    "    embeds_dataset = matrioskaidx2embeds[matrioska_idx].filter(\n",
    "        lambda x: x[\"y\"] in EVALUATION_CLASSES,\n",
    "    )\n",
    "    embeds_dataset.set_format(type=\"torch\", columns=[\"embeds\", \"y\"])\n",
    "\n",
    "    eval_train_loader = DataLoader(\n",
    "        embeds_dataset[\"train\"],\n",
    "        batch_size=64,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    eval_test_loader = DataLoader(\n",
    "        embeds_dataset[\"test\"],\n",
    "        batch_size=64,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    model = Classifier(\n",
    "        input_dim=embeds_dataset[\"train\"][\"embeds\"].size(1),\n",
    "        num_classes=len(EVALUATION_CLASSES),\n",
    "        lr=1e-4,\n",
    "        deep=True,\n",
    "        x_feature=\"embeds\",\n",
    "        y_feature=\"y\",\n",
    "    )\n",
    "\n",
    "    callbacks: List[Callback] = build_callbacks(cfg.train.callbacks)\n",
    "\n",
    "    storage_dir: str = cfg.core.storage_dir\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=storage_dir,\n",
    "        logger=None,\n",
    "        fast_dev_run=False,\n",
    "        gpus=1,\n",
    "        precision=32,\n",
    "        max_epochs=50,\n",
    "        accumulate_grad_batches=1,\n",
    "        num_sanity_val_steps=2,\n",
    "        gradient_clip_val=10.0,\n",
    "        val_check_interval=1.0,\n",
    "    )\n",
    "    trainer.fit(model, train_dataloaders=eval_train_loader, val_dataloaders=eval_test_loader)\n",
    "\n",
    "    classifier_model = trainer.model.eval().cpu().requires_grad_(False)\n",
    "    run_results = trainer.test(model=classifier_model, dataloaders=eval_test_loader)[0]\n",
    "\n",
    "    performance.extend(\n",
    "        (\n",
    "            Result(\n",
    "                matrioska_idx=matrioska_idx,\n",
    "                num_train_classes=len(matrioskaclasses[matrioska_idx]),\n",
    "                metric_name=\"test_accuracy\",\n",
    "                score=run_results[\"accuracy\"],\n",
    "            ),\n",
    "            Result(\n",
    "                matrioska_idx=matrioska_idx,\n",
    "                num_train_classes=len(matrioskaclasses[matrioska_idx]),\n",
    "                metric_name=\"test_f1\",\n",
    "                score=run_results[\"f1\"],\n",
    "            ),\n",
    "            Result(\n",
    "                matrioska_idx=matrioska_idx,\n",
    "                num_train_classes=len(matrioskaclasses[matrioska_idx]),\n",
    "                metric_name=\"test_loss\",\n",
    "                score=run_results[\"test_loss\"],\n",
    "            ),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "perf = pd.DataFrame(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "perf = perf[perf[\"metric_name\"] == \"test_accuracy\"]\n",
    "\n",
    "fig = px.scatter(perf, x=\"matrioska_idx\", y=\"score\")\n",
    "\n",
    "fig.update_layout(yaxis_title=\"accuracy\", xaxis_title=\"# classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf.to_json(PROJECT_ROOT / \"paper_results\" / \"matrioska.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "la",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
