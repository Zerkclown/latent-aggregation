{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "\n",
    "initialize(version_base=None, config_path=str(\"../conf\"), job_name=\"matrioska_learning\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_core.common import PROJECT_ROOT\n",
    "\n",
    "# Instantiate torchvision dataset\n",
    "cfg = compose(config_name=\"matrioska_learning\", overrides=[])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from la.utils.io_utils import add_ids_to_dataset, load_data\n",
    "from la.utils.io_utils import preprocess_dataset\n",
    "\n",
    "\n",
    "original_dataset = dataset = load_data(cfg).shard(num_shards=10, index=0)  # TODO remove sharding when done develop\n",
    "dataset = preprocess_dataset(dataset, cfg)\n",
    "dataset = add_ids_to_dataset(dataset)\n",
    "img_size = dataset[\"train\"][0][\"x\"].size[1]\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define matrioska datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf specific variables\n",
    "# (if a dataset change is needed, it is enough to redefine these variables...)\n",
    "class_names = original_dataset[\"train\"].features[\"label\"].names\n",
    "class_idxs = [original_dataset[\"train\"].features[\"label\"].str2int(class_name) for class_name in class_names]\n",
    "\n",
    "class_names, class_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define matrioska parameters... just start with the first two classes\n",
    "MATRIOSKA_START_NCLASSES = [0, 1]\n",
    "remanining_classes = sorted((set(class_idxs) - set(MATRIOSKA_START_NCLASSES)))\n",
    "MATRIOSKA_START_NCLASSES, remanining_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate matrioska classes\n",
    "matrioskaclasses = [set(MATRIOSKA_START_NCLASSES + remanining_classes[:i]) for i in range(len(remanining_classes) + 1)]\n",
    "matrioskaclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate associated datasets\n",
    "# TODO: do we want to have the same number of samples in all the datasets?\n",
    "# I think not. This is more fair, if this works we are in the worst case scenario.\n",
    "matrioskaidx2dataset = {\n",
    "    i: dataset.filter(lambda row: row[\"y\"] in matrioskaclasses[i]) for i in range(len(matrioskaclasses))\n",
    "}\n",
    "\n",
    "# Note that we are using the prefix convention for the classes, thus we have consistency\n",
    "# between local and global classes ids... let's stay with that it is easier\n",
    "matrioskaidx2dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train matrioska models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "matrioskaidx2model = {}\n",
    "\n",
    "\n",
    "for i in range(len(matrioskaclasses)):\n",
    "    print(f\"Training model {i}...\")\n",
    "\n",
    "    model: pl.LightningModule = hydra.utils.instantiate(\n",
    "        cfg.nn.model,\n",
    "        _recursive_=False,\n",
    "        num_classes=len(matrioskaclasses[i]),\n",
    "        model=cfg.nn.model.model,\n",
    "        input_dim=img_size,\n",
    "    )\n",
    "\n",
    "    processed_dataset = matrioskaidx2dataset[i].map(\n",
    "        desc=f\"Preprocessing samples\",\n",
    "        function=lambda x: {\"x\": model.transform_func(x[\"x\"])},\n",
    "    )\n",
    "    processed_dataset.set_format(type=\"torch\", columns=[\"x\", \"y\"])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        processed_dataset[\"train\"],\n",
    "        batch_size=64,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        processed_dataset[\"test\"],\n",
    "        batch_size=64,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        max_epochs=3,\n",
    "        logger=None,\n",
    "        # callbacks=[RichProgressBar()],\n",
    "        enable_progress_bar=True,\n",
    "    )\n",
    "    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "    matrioskaidx2model[i] = trainer.model.eval().cpu().requires_grad_(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate matrioska models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which classes to evaluate on -- it may be interesting to change this\n",
    "EVALUATION_CLASSES = MATRIOSKA_START_NCLASSES\n",
    "EVALUATION_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluation dataset according to chosen classes\n",
    "eval_dataset = dataset.filter(lambda row: row[\"y\"] in set(EVALUATION_CLASSES))\n",
    "eval_dataset = eval_dataset.map(\n",
    "    desc=f\"Preprocessing samples\",\n",
    "    function=lambda x: {\"x\": model.transform_func(x[\"x\"])},\n",
    ")\n",
    "eval_dataset.set_format(type=\"torch\", columns=[\"x\", \"y\"])\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    eval_dataset[\"test\"],\n",
    "    batch_size=64,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=3,\n",
    "    logger=None,\n",
    "    # callbacks=[RichProgressBar()],\n",
    "    enable_progress_bar=True,\n",
    ")\n",
    "\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Result:\n",
    "    matrioska_idx: int\n",
    "    test_acc: float\n",
    "    test_loss: float\n",
    "    clusterer: str\n",
    "    v_measure_score: float\n",
    "    adjusted_mutual_info_score: float\n",
    "    adjusted_rand_score: float\n",
    "    completeness_score: float\n",
    "    fowlkes_mallows_score: float\n",
    "    homogeneity_completeness_v_measure: float\n",
    "    homogeneity_score: float\n",
    "    mutual_info_score: float\n",
    "    normalized_mutual_info_score: float\n",
    "    rand_score: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, BisectingKMeans\n",
    "import sklearn\n",
    "import torch\n",
    "\n",
    "\n",
    "model = matrioskaidx2model[0]\n",
    "\n",
    "\n",
    "def compute_eval_embedings(model, eval_loader):\n",
    "    eval_embeddings = []\n",
    "    eval_labels = []\n",
    "    for batch in eval_loader:\n",
    "        out = model(batch[\"x\"])\n",
    "        eval_embeddings.append(out[\"embeds\"])\n",
    "        eval_labels.append(batch[\"y\"])\n",
    "\n",
    "    eval_embeddings = torch.cat(eval_embeddings, dim=0)\n",
    "    eval_labels = torch.cat(eval_labels, dim=0)\n",
    "    return eval_embeddings.detach().cpu().numpy(), eval_labels.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "clusterizer = {\n",
    "    \"kmeans\": lambda embeds: KMeans(n_clusters=len(EVALUATION_CLASSES)).fit(embeds).labels_,\n",
    "    \"bisect-kmeans\": lambda embeds: BisectingKMeans(n_clusters=len(EVALUATION_CLASSES)).fit(embeds).labels_,\n",
    "}\n",
    "\n",
    "clustering_metric = {\n",
    "    \"v_measure_score\": lambda x, y_pred, y_true: sklearn.metrics.v_measure_score(y_true, y_pred),\n",
    "    \"adjusted_mutual_info_score\": lambda x, y_pred, y_true: sklearn.metrics.adjusted_mutual_info_score(y_true, y_pred),\n",
    "    \"adjusted_rand_score\": lambda x, y_pred, y_true: sklearn.metrics.adjusted_rand_score(y_true, y_pred),\n",
    "    \"completeness_score\": lambda x, y_pred, y_true: sklearn.metrics.completeness_score(y_true, y_pred),\n",
    "    \"fowlkes_mallows_score\": lambda x, y_pred, y_true: sklearn.metrics.fowlkes_mallows_score(y_true, y_pred),\n",
    "    \"homogeneity_completeness_v_measure\": lambda x, y_pred, y_true: sklearn.metrics.homogeneity_completeness_v_measure(\n",
    "        y_true, y_pred\n",
    "    ),\n",
    "    \"homogeneity_score\": lambda x, y_pred, y_true: sklearn.metrics.homogeneity_score(y_true, y_pred),\n",
    "    \"mutual_info_score\": lambda x, y_pred, y_true: sklearn.metrics.mutual_info_score(y_true, y_pred),\n",
    "    \"normalized_mutual_info_score\": lambda x, y_pred, y_true: sklearn.metrics.normalized_mutual_info_score(\n",
    "        y_true, y_pred\n",
    "    ),\n",
    "    \"rand_score\": lambda x, y_pred, y_true: sklearn.metrics.rand_score(y_true, y_pred),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = []\n",
    "for i in range(len(matrioskaidx2model)):\n",
    "    result = trainer.test(model=matrioskaidx2model[i], dataloaders=eval_loader)[0]\n",
    "\n",
    "    eval_embeddings, eval_labels = compute_eval_embedings(model, eval_loader)\n",
    "\n",
    "    for clusterizer_name, clusterizer_func in clusterizer.items():\n",
    "        clustering_labels = clusterizer[clusterizer_name](eval_embeddings)\n",
    "\n",
    "        metrics = {\n",
    "            metric_name: metric_func(x=eval_embeddings, y_pred=clustering_labels, y_true=eval_labels)\n",
    "            for metric_name, metric_func in clustering_metric.items()\n",
    "        }\n",
    "\n",
    "        performance.append(\n",
    "            Result(\n",
    "                matrioska_idx=i,\n",
    "                test_acc=result[\"acc/test\"],\n",
    "                test_loss=result[\"loss/test\"],\n",
    "                clusterer=clusterizer_name,\n",
    "                **metrics\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "perf = pd.DataFrame(performance)\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf.to_csv(PROJECT_ROOT / \"perf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = pd.read_csv(PROJECT_ROOT / \"perf.csv\")\n",
    "perf[\"ntrain_classes\"] = perf[\"matrioska_idx\"] + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(\n",
    "    perf,\n",
    "    facet_col=\"clusterer\",\n",
    "    x=\"ntrain_classes\",\n",
    "    y=\"test_acc\",\n",
    "    labels={\"matrioska_idx\": \"Number of classes trained on\", \"test_acc\": \"Test accuracy\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    perf,\n",
    "    facet_col=\"clusterer\",\n",
    "    x=\"ntrain_classes\",\n",
    "    y=\"v_measure_score\",\n",
    "    labels={\"matrioska_idx\": \"Number of classes trained on\", \"test_acc\": \"Test accuracy\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    perf,\n",
    "    facet_col=\"clusterer\",\n",
    "    x=\"ntrain_classes\",\n",
    "    y=\"adjusted_mutual_info_score\",\n",
    "    labels={\"matrioska_idx\": \"Number of classes trained on\", \"test_acc\": \"Test accuracy\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    perf,\n",
    "    facet_col=\"clusterer\",\n",
    "    x=\"ntrain_classes\",\n",
    "    y=\"adjusted_rand_score\",\n",
    "    labels={\"matrioska_idx\": \"Number of classes trained on\", \"test_acc\": \"Test accuracy\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    perf,\n",
    "    facet_col=\"clusterer\",\n",
    "    x=\"ntrain_classes\",\n",
    "    y=\"completeness_score\",\n",
    "    labels={\"matrioska_idx\": \"Number of classes trained on\", \"test_acc\": \"Test accuracy\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    perf,\n",
    "    facet_col=\"clusterer\",\n",
    "    x=\"ntrain_classes\",\n",
    "    y=\"fowlkes_mallows_score\",\n",
    "    labels={\"matrioska_idx\": \"Number of classes trained on\", \"test_acc\": \"Test accuracy\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y not a number\n",
    "# px.scatter(\n",
    "#     perf,\n",
    "#     facet_col=\"clusterer\",\n",
    "#     x=\"ntrain_classes\",\n",
    "#     y=\"homogeneity_completeness_v_measure\",\n",
    "#     labels={\"matrioska_idx\": \"Number of classes trained on\", \"test_acc\": \"Test accuracy\"},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    perf,\n",
    "    facet_col=\"clusterer\",\n",
    "    x=\"ntrain_classes\",\n",
    "    y=\"homogeneity_score\",\n",
    "    labels={\"matrioska_idx\": \"Number of classes trained on\", \"test_acc\": \"Test accuracy\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    perf,\n",
    "    facet_col=\"clusterer\",\n",
    "    x=\"ntrain_classes\",\n",
    "    y=\"mutual_info_score\",\n",
    "    labels={\"matrioska_idx\": \"Number of classes trained on\", \"test_acc\": \"Test accuracy\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    perf,\n",
    "    facet_col=\"clusterer\",\n",
    "    x=\"ntrain_classes\",\n",
    "    y=\"normalized_mutual_info_score\",\n",
    "    labels={\"matrioska_idx\": \"Number of classes trained on\", \"test_acc\": \"Test accuracy\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    perf,\n",
    "    facet_col=\"clusterer\",\n",
    "    x=\"ntrain_classes\",\n",
    "    y=\"rand_score\",\n",
    "    labels={\"matrioska_idx\": \"Number of classes trained on\", \"test_acc\": \"Test accuracy\"},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "la",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
