{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "\n",
    "initialize(version_base=None, config_path=str(\"../conf\"), job_name=\"matrioska_learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_core.common import PROJECT_ROOT\n",
    "\n",
    "# Instantiate torchvision dataset\n",
    "cfg = compose(config_name=\"matrioska_learning\", overrides=[])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load matrioska embeddings\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate matrioska models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which classes to evaluate on -- it may be interesting to change this\n",
    "EVALUATION_CLASSES = {0, 1}\n",
    "EVALUATION_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Result:\n",
    "    matrioska_idx: int\n",
    "    num_train_classes: int\n",
    "    metric_name: str\n",
    "    score: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from nn_core.callbacks import NNTemplateCore\n",
    "from nn_core.model_logging import NNLogger\n",
    "from nn_core.serialization import NNCheckpointIO\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Callback\n",
    "from la.pl_modules.classifier import Classifier\n",
    "\n",
    "from la.utils.utils import build_callbacks\n",
    "\n",
    "performance = []\n",
    "for matrioska_idx, embeds in matrioskaidx2embeds.items():\n",
    "    embeds_dataset = matrioskaidx2embeds[matrioska_idx].filter(\n",
    "        lambda x: x[\"y\"] in EVALUATION_CLASSES,\n",
    "    )\n",
    "    embeds_dataset.set_format(type=\"torch\", columns=[\"embeds\", \"y\"])\n",
    "\n",
    "    eval_train_loader = DataLoader(\n",
    "        embeds_dataset[\"train\"],\n",
    "        batch_size=64,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    eval_test_loader = DataLoader(\n",
    "        embeds_dataset[\"test\"],\n",
    "        batch_size=64,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    model = Classifier(\n",
    "        input_dim=embeds_dataset[\"train\"][\"embeds\"].size(1),\n",
    "        num_classes=len(EVALUATION_CLASSES),\n",
    "        lr=1e-4,\n",
    "        deep=True,\n",
    "        x_feature=\"embeds\",\n",
    "        y_feature=\"y\",\n",
    "    )\n",
    "\n",
    "    callbacks: List[Callback] = build_callbacks(cfg.train.callbacks)\n",
    "\n",
    "    storage_dir: str = cfg.core.storage_dir\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=storage_dir,\n",
    "        logger=None,\n",
    "        fast_dev_run=False,\n",
    "        gpus=1,\n",
    "        precision=32,\n",
    "        max_epochs=50,\n",
    "        accumulate_grad_batches=1,\n",
    "        num_sanity_val_steps=2,\n",
    "        gradient_clip_val=10.0,\n",
    "        val_check_interval=1.0,\n",
    "    )\n",
    "    trainer.fit(model, train_dataloaders=eval_train_loader, val_dataloaders=eval_test_loader)\n",
    "\n",
    "    classifier_model = trainer.model.eval().cpu().requires_grad_(False)\n",
    "    run_results = trainer.test(model=classifier_model, dataloaders=eval_test_loader)[0]\n",
    "\n",
    "    performance.extend(\n",
    "        (\n",
    "            Result(\n",
    "                matrioska_idx=matrioska_idx,\n",
    "                num_train_classes=None,\n",
    "                metric_name=\"test_accuracy\",\n",
    "                score=run_results[\"accuracy\"],\n",
    "            ),\n",
    "            Result(\n",
    "                matrioska_idx=matrioska_idx,\n",
    "                num_train_classes=None,\n",
    "                metric_name=\"test_f1\",\n",
    "                score=run_results[\"f1\"],\n",
    "            ),\n",
    "            Result(\n",
    "                matrioska_idx=matrioska_idx,\n",
    "                num_train_classes=None,\n",
    "                metric_name=\"test_loss\",\n",
    "                score=run_results[\"test_loss\"],\n",
    "            ),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "perf = pd.DataFrame(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(perf, x=\"matrioska_idx\", y=\"score\", color=\"metric_name\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "la",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
